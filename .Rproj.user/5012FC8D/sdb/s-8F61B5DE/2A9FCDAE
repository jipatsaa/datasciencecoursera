{
    "contents" : "####################\n## FILE NAME: run_analysis.R\n## \n## GOAL: run_analysis.R that does the following: \n## 1. Merges the training and the test sets to create one data set.\n## 2. Extracts only the measurements on the mean and standard deviation for each measurement. \n## 3. Uses descriptive activity names to name the activities in the data set\n## 4. Appropriately labels the data set with descriptive variable names. \n## 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.\n##\n## PRE-CONDITIONS:\n##\n## POST-CONDITIONS:\n## - \"data\" directory is created, and both the original data and the tidy data are placed there\n## \n####################\n\n## -----------------------------\n## Download and unzip the \"Human Activity Recognition Using Smartphones Data Set\" \n## -----------------------------\n##### You can write the function in a separate file and next import the function with source\n# Goal: download a file from a given url into a given directory and with a given name\ndownloadFromURL <- function  (fileUrl=\"http://dir.csv\", workdirPath=\".\", fileName=\"dataFile\")\n{\n  ## Step 0: Checking for and creating directories\n  if(!file.exists(workdirPath))\n  {\n    dir.create(workdirPath)\n  }\n  \n  ## Step 1: download the data file\n  filePath=paste(workdirPath,fileName,sep=\"/\")\n  if(!file.exists(filePath))\n  {\n    download.file(fileUrl, destfile=filePath,method=\"curl\")\n    dateDownloaded <- date()\n    print(paste(\"INFO: the data file downloaded on: \", dateDownloaded))\n  }\n  else{\n    print(\"Saionara baby!\")\n  }\n}\n# source(\"downloadFromURL.R\")\n#####\nfileUrl <- \"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip\"\ndataDir <- \"./data\" # unzip EZ DABIL HAU  ../data denean :_!\nfileNameZIP <- \"UCI_HAR_Dataset.zip\"\nfilePathZIP <- paste(dataDir,fileNameZIP,sep=\"/\")\n\ndownloadFromURL(fileUrl,workdirPath=dataDir,fileName=fileNameZIP)\nunzip(zipfile=filePathZIP, exdir=dataDir) \n\n\n## -----------------------------\n## Read the data into R objects\n## -----------------------------\n# Get the subjects\nsubject_test  <- read.table(paste(dataDir,\"UCI HAR Dataset/test/subject_test.txt\",sep=\"/\"))\nsubject_train <- read.table(paste(dataDir,\"UCI HAR Dataset/train/subject_train.txt\",sep=\"/\"))\n# Get the features\nx_test  <- read.table(paste(dataDir,\"UCI\\ HAR\\ Dataset/test/X_test.txt\",sep=\"/\"))\nx_train <- read.table(paste(dataDir,\"UCI\\ HAR\\ Dataset/train/X_train.txt\",sep=\"/\"))\n\n# Get the activities and change each code by the appropriate label\ny_test  <- read.table(paste(dataDir,\"UCI\\ HAR\\ Dataset/test/y_test.txt\",sep=\"/\"))\ny_train <- read.table(paste(dataDir,\"UCI\\ HAR\\ Dataset/train/y_train.txt\",sep=\"/\"))\n#\nylabels <- read.table(paste(dataDir,\"UCI HAR Dataset/activity_labels.txt\",sep=\"/\")) # here the label is a factor of a number-code and activity-label\n#\nfor (i in ylabels$V1) {\n  y_test$V1[y_test$V1 == i]   <- as.character(ylabels$V2[i])\n  y_train$V1[y_train$V1 == i] <- as.character(ylabels$V2[i])\n}\n\n# Column-bind: subject, features and activity\nx_y_test  <- cbind(subject_test, x_test, y_test) \nx_y_train <- cbind(subject_train, x_train, y_train) \n\n\n## -----------------------------\n## Merge the training and the test sets to create one data set.\n## -----------------------------\ndata <- rbind(x_y_train,x_y_test)\n\n\n## -----------------------------\n## Arrange the names of the: subject, features, activity\n## -----------------------------\n# Read the names of the features\nfeatures <- read.table(paste(dataDir,\"UCI HAR Dataset/features.txt\",sep=\"/\")) # Honek bi atributu ditu posizioa eta izena\nfeatures <- features[2] # amaieran, frame motakoa da\nnames(features) <- c(\"featName\")\n# Add the names: subject, features, activity\nnames(data)  <- c(\"subject\",as.character(features$featName),\"activity\")\n\n\n\n\n## -----------------------------\n## Remove useless objects (otherwise, my old laptop may run out of memory:)\n## -----------------------------\nremove(x_y_train,x_y_test,x_train,x_test,y_train,y_test,ylabels,features,subject_test,subject_train)\n\n\n\n## -----------------------------\n## Select the features containing information about either \"mean\" or \"std\" or \"subject\" (first) or \"activity\" (last)\n## -----------------------------\n# meanFeatIdx <- grep(\"mean\", names(data), ignore.case = TRUE)\n# stdFeatIdx <- grep(\"std\", names(data), ignore.case = TRUE)\n# subjIdx <- grep(\"subject\", names(data), ignore.case = TRUE)\n# actIdx <- grep(\"activity\", names(data), ignore.case = TRUE)\n# usefulFeatIdx <- sort(unique(c(actIdx,subjIdx, meanFeatIdx, stdFeatIdx)))\n# # AURREKOAREN ORDEZ \nusefulFeatIdx <- unique(grep(\"mean|std|subject|activity\", names(data), ignore.case = TRUE))\n# \ndata  <- subset(data, select=usefulFeatIdx)\n# Write the data into an output file\noutFile1=\"outFile_Tidy_1.csv\"\nwrite.csv(data, file=paste(dataDir, outFile1 ,sep=\"/\"))\n#outFile1=\"outFile_Tidy_1.txt\"\n#write.table(data, file=paste(dataDir, outFile1 ,sep=\"/\"), sep=\",\", row.name=FALSE)\n\n\n## -----------------------------\n## Create a second, independent tidy data set with\n## the average of each variable for each activity and each subject\n## -----------------------------\nAvVble_perSubject <- by(data, INDICES=list(SUBJECT=data$subject,ACTIVITY=data$activity), FUN=\n     function(x){\n       y <- subset(x, select=-c(subject,activity)) # Do not make the mean neither of the subject nor of the activity:!\n       apply(y, 2, mean) # Remember: 1 indicates rows, 2 indicates columns, c(1, 2) indicates rows and columns.\n     } \n   )\n# # AURREKOAREN ORDEZ, baina subset(x, select=-c(subject,activity)) egiteke\n#tmp <- aggregate(data,   by(data, INDICES=list(SUBJECT=data$subject,ACTIVITY=data$activity)), FUN=mean)\n#AvVble_perSubject <- subset(tmp, select=-c(subject,activity) )\nprint(\"There you are the the average of each variable for each activity and each subject\")\nAvVble_perSubject\n# using dplyr will be much easier\n#library(dplyr)\n#dft_data <- tbl_df(data)\n#by_subject_act <- group_by(dft_data, subject, activity)\n#summarizedData <- summary(by_subject_act)\n\n# Write the data into an output file\n# Please upload your data set as a txt file created with write.table() using row.name=FALSE \n# outFile2=\"outFile_Tidy_2.csv\"\n# write.csv(AvVble_perSubject, file=paste(dataDir, outFile2 ,sep=\"/\"))\noutFile2=\"outFile_Tidy_2.txt\"\nwrite.table(AvVble_perSubject, file=paste(dataDir, outFile2 ,sep=\",\"), sep=\"/\", row.name=FALSE)\n\n\n\n",
    "created" : 1419196530259.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "91705142",
    "id" : "2A9FCDAE",
    "lastKnownWriteTime" : 1419090177,
    "path" : "~/Dropbox/3_Getting_and_Cleaning_Data/project/apr_v0/src/run_analysis.R",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}